{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_of_documents = [\n",
    "    \"Take a leisurely walk in the park and enjoy the fresh air.\",\n",
    "    \"Visit a local museum and discover something new.\",\n",
    "    \"Attend a live music concert and feel the rhythm.\",\n",
    "    \"Go for a hike and admire the natural scenery.\",\n",
    "    \"Have a picnic with friends and share some laughs.\",\n",
    "    \"Explore a new cuisine by dining at an ethnic restaurant.\",\n",
    "    \"Take a yoga class and stretch your body and mind.\",\n",
    "    \"Join a local sports league and enjoy some friendly competition.\",\n",
    "    \"Attend a workshop or lecture on a topic you're interested in.\",\n",
    "    \"Visit an amusement park and ride the roller coasters.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I don't like to hike\"\n",
    "relevant_document = return_response(user_input, corpus_of_documents)\n",
    "print(relevant_document)\n",
    "# https://github.com/jmorganca/ollama/blob/main/docs/api.md\n",
    "full_response = []\n",
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "This is the recommended activity: {relevant_document}\n",
    "The user input is: {user_input}\n",
    "Compile a recommendation to the user based on the recommended activity and the user input.\n",
    "\"\"\"\n",
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"llama2\",\n",
    "    \"prompt\": prompt.format(user_input=user_input, relevant_document=relevant_document)\n",
    "}\n",
    "print(data)\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "try:\n",
    "    for line in response.iter_lines():\n",
    "        # filter out keep-alive new lines\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            print(decoded_line)\n",
    "            # print(decoded_line['response'])  # uncomment to results, token by token\n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Semantic Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\NailFerroukhi\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:435: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at ..\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    }
   ],
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "doc_embeddings = model.encode(corpus_of_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.07121076 -0.01088004  0.11746486 ...  0.0141492  -0.13175769\n",
      "  -0.00402592]\n",
      " [ 0.04881531 -0.03166635  0.07468717 ... -0.0627827  -0.11120288\n",
      "   0.03045148]\n",
      " [ 0.05019964 -0.09127749  0.08517752 ...  0.01286449 -0.07415231\n",
      "  -0.06140353]\n",
      " ...\n",
      " [ 0.05416268 -0.03030901  0.02475947 ... -0.01272298 -0.06512283\n",
      "   0.05848261]\n",
      " [-0.00401902 -0.04562394 -0.00900758 ...  0.03939749 -0.12731634\n",
      "   0.05255727]\n",
      " [ 0.05046039  0.01430449  0.0878795  ... -0.01778715 -0.05246405\n",
      "  -0.02887326]]\n"
     ]
    }
   ],
   "source": [
    "print(doc_embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cosine similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What's the best outside activity?\"\n",
    "query_embedding = model.encode([query])\n",
    "similarities = cosine_similarity(query_embedding, doc_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.50235206 0.3282639  0.31544408 0.50193346 0.44371963 0.18485206\n",
      "  0.2104584  0.25540653 0.22164026 0.45777765]]\n"
     ]
    }
   ],
   "source": [
    "print(similarities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ranking and Recommending Activities\n",
    "\n",
    "Sorting Similarity Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed = list(enumerate(similarities[0]))\n",
    "sorted_index = sorted(indexed, key=lambda x: x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.50235206), (3, 0.50193346), (9, 0.45777765), (4, 0.44371963), (1, 0.3282639), (2, 0.31544408), (7, 0.25540653), (8, 0.22164026), (6, 0.2104584), (5, 0.18485206)]\n"
     ]
    }
   ],
   "source": [
    "print(sorted_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecting Top-Ranked Documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.50 => Take a leisurely walk in the park and enjoy the fresh air.\n",
      "0.50 => Go for a hike and admire the natural scenery.\n",
      "0.46 => Visit an amusement park and ride the roller coasters.\n",
      "0.44 => Have a picnic with friends and share some laughs.\n",
      "0.33 => Visit a local museum and discover something new.\n",
      "0.32 => Attend a live music concert and feel the rhythm.\n",
      "0.26 => Join a local sports league and enjoy some friendly competition.\n",
      "0.22 => Attend a workshop or lecture on a topic you're interested in.\n",
      "0.21 => Take a yoga class and stretch your body and mind.\n",
      "0.18 => Explore a new cuisine by dining at an ethnic restaurant.\n"
     ]
    }
   ],
   "source": [
    "recommended_documents = []\n",
    "for value, score in sorted_index:\n",
    "    formatted_score = \"{:.2f}\".format(score)\n",
    "    print(f\"{formatted_score} => {corpus_of_documents[value]}\")\n",
    "    if score > 0.3:\n",
    "        recommended_documents.append(corpus_of_documents[value])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Integrating with a Language Model for Natural Responses\n",
    "\n",
    "The Prompt Engineering Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a bot that makes recommendations for activities. You answer in very short sentences and do not include extra information.\n",
    "These are potential activities:\n",
    "{recommended_activities}\n",
    "The user's query is: {user_input}\n",
    "Provide the user with 2 recommended activities based on their query.\n",
    "\"\"\"\n",
    "recommended_activities = \"\\n\".join(recommended_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating the Final Recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_input = \"I like to hike\"\n",
    "full_prompt = prompt.format(user_input=user_input, recommended_activities=recommended_activities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then run model execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Great! Based on your interest in hiking, here are two recommended activities for you:\n",
      "\n",
      "1. Go for a hike and admire the natural scenery.\n",
      "2. Visit an amusement park and ride the roller coasters.\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "url = 'http://localhost:11434/api/generate'\n",
    "data = {\n",
    "    \"model\": \"llama2\",\n",
    "    \"prompt\": full_prompt\n",
    "}\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(url, data=json.dumps(data), headers=headers, stream=True)\n",
    "full_response=[]\n",
    "try:\n",
    "    count = 0\n",
    "    for line in response.iter_lines():\n",
    "        #filter out keep-alive new lines\n",
    "        # count += 1\n",
    "        # if count % 5== 0:\n",
    "        #     print(decoded_line['response']) # print every fifth token\n",
    "        if line:\n",
    "            decoded_line = json.loads(line.decode('utf-8'))\n",
    "            \n",
    "            full_response.append(decoded_line['response'])\n",
    "finally:\n",
    "    response.close()\n",
    "print(''.join(full_response))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
