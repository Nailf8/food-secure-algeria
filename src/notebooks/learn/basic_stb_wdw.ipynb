{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pypdf\n",
    "%pip install llama_index\n",
    "%pip install llama-index-llms-ollama\n",
    "%pip install llama-index-embeddings-langchain\n",
    "%pip install langchain-huggingface\n",
    "%pip install ragas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, ServiceContext\n",
    "from llama_index.core.prompts.prompts import SimpleInputPrompt\n",
    "\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from llama_index.embeddings.langchain import LangchainEmbedding\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Ollama(model=\"llama3\", request_timeout=500.0)\n",
    "Settings.embed_model = LangchainEmbedding(HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents=SimpleDirectoryReader(\"../silver/data\").load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic Retreiver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SentenceSplitter(chunk_size=1024)\n",
    "nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='node_563', embedding=None, metadata={'file_path': 'c:\\\\Users\\\\NailFerroukhi\\\\Desktop\\\\dauphine\\\\thesis\\\\basic_rag\\\\notebooks\\\\..\\\\silver\\\\data\\\\output.txt', 'file_name': 'output.txt', 'file_type': 'text/plain', 'file_size': 2336905, 'creation_date': '2024-07-25', 'last_modified_date': '2024-08-01'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='e4ec6066-24e1-475f-8210-0d038a584a75', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'c:\\\\Users\\\\NailFerroukhi\\\\Desktop\\\\dauphine\\\\thesis\\\\basic_rag\\\\notebooks\\\\..\\\\silver\\\\data\\\\output.txt', 'file_name': 'output.txt', 'file_type': 'text/plain', 'file_size': 2336905, 'creation_date': '2024-07-25', 'last_modified_date': '2024-08-01'}, hash='8b20f73771700d83f58a3abf765ca807488593b79803ca0d9214b8fbdd4092ca'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='5941dba2-16d1-4f6a-9049-2fc5cbb5046e', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'c:\\\\Users\\\\NailFerroukhi\\\\Desktop\\\\dauphine\\\\thesis\\\\basic_rag\\\\notebooks\\\\..\\\\silver\\\\data\\\\output.txt', 'file_name': 'output.txt', 'file_type': 'text/plain', 'file_size': 2336905, 'creation_date': '2024-07-25', 'last_modified_date': '2024-08-01'}, hash='e6fa5695921876bb2e03aece1becb3adf987707a9c766608f2965428d2d16796'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='be0938de-e9d7-41bd-a540-efbf1c533761', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='4236e3f0617f982a5e843c140d7f12a5d0d20280afa98a504d0069093c76dd9c')}, text='Ceci sera possible à travers un examen des nuages de points de la variable à expliquer et des variables explicatives prises deux à deux. De ces quatre nuages de points, celui avec les superficies est celui qui paraît le plus corrélé avec la valeur ajoutée.A part les quatre premières années (2000 à 2003) où l’on remarque qu’on est en présence d’une droite presque verticale ce qui reflète une certaine insensibilité de la valeur ajoutée malgré l’augmentation des superficies cultivées.  Graphe 65 : Relation de la valeur ajoutée avec les autres variables du modèle 020,00040,00060,00080,000100,000300,000 500,000 700,000 900,000Valeur ajoutée agricoleSOUT_PROD050,000100,000150,000200,000300,000 500,000 700,000 900,000Valeur ajoutée agricoleSOUT_CONS4,400,0004,600,0004,800,0005,000,0005,200,0005,400,0005,600,000300,000 500,000 700,000 900,000Valeur ajoutée agricoleSUPERF3,0003,5004,0004,5005,0005,500300,000 500,000 700,000 900,000Valeur ajoutée agricolePLUV  CHAPITRE 5 : EVALUATION DES EFFETS DES POLITIQUES DE SOUTIENS DE L’AGRICULTURE ET LA PECHE SUR LA SECURITE ALIMENTAIRE  -Partie III Page | 486 A partir de 2004, on remarque une relation croissante entre les superficies cultivées et la valeur ajoutée. La relation avec les subventions est plus contrastée. La valeur ajoutée est plus sensible aux subventions adressées aux producteurs que celles adressées aux consommateurs. En effet, le coefficient de corrélation entre la valeur ajoutée et la subvention aux producteurs est de 0,89. En revanche celle avec les subventions aux consommateurs est beaucoup plus basse (0,74). Ce constat est confirmé avec l’examen des deux nuages de points. Enfin le dernier nuage est relatif à la relation entre la pluviométrie et la valeur ajoutée. C’est le nuage le plus épars ce qui signifie que cette variable est celle qui explique le moins la variable à expliquer (cf. graphe 65). L’estimation du modèle présenté ci-dessus a donné les résultats suivants  :  Le pouvoir explicatif du modèle est satisfaisant. L’ensemble des variables explicatives prises ensemble y compris la constante expliquent 96% des variations de la valeur ajoutée. Le signe négatif de la constante renvoie au fait qu’il ne peut exister une valeur ajoutée sans l’ensemble des variables incluses dans le modèle. Ce qui constitue une valeur cohérente et plausible. Pour les autres variables, tous leurs signes sont positifs et conformes à ce qui est attendu intuitivement. Mais en termes de significativité, ni les variables relatives aux soutiens, ni celles à la pluviométrie ne sont significatives même à un seuil de 10%. Seule la variable « superficie » est très significative. En termes de valeurs d’élasticités obtenues, les valeurs estimées sont plausibles.  Comme attendu, la valeur ajoutée est en premier très sensible à l’augmentation des surfaces emblavées. Son élasticité est de 4,1%. En d’autres termes, une augmentation des superficies de 1% induirait une augmentation de la valeur ajoutée de plus de 4%. En second lieu, la valeur ajoutée est sensible aux subventions aux producteurs et aux consommateurs dans des valeurs assez proches (respectivement 0,05% et 0,03%). Cette hiérarchie reflète l’effet direct et indirect de l’impact de ces deux différentes subventions sur la valeur ajoutée agricole. Ces premiers résultats sont limités car la période d’estimation va seulement de 2006 à 2017.', mimetype='text/plain', start_char_idx=1543842, end_char_idx=1547218, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes[563]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, the node ids are set to random uuids. To ensure same id's per run, we manually set them.\n",
    "for idx, node in enumerate(nodes):\n",
    "    node.id_ = f\"node_{idx}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index = VectorStoreIndex(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_index.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_nodes = retriever.retrieve(\"زراعة\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.response.notebook_utils import display_source_node\n",
    "\n",
    "for node in retrieved_nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chunk References: Smaller Child Chunks Referring to Bigger Parent Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.retrievers import RecursiveRetriever\n",
    "from llama_index.core.node_parser import SimpleNodeParser\n",
    "from llama_index.core.schema import IndexNode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_parser = SimpleNodeParser.from_defaults(chunk_size=1024, chunk_overlap=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceSplitter(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000179E12A9360>, id_func=<function default_id_func at 0x00000179C48CE320>, chunk_size=1024, chunk_overlap=20, separator=' ', paragraph_separator='\\n\\n\\n', secondary_chunking_regex='[^,.;。？！]+[,.;。？！]?')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_chunk_sizes = [128, 256, 512]\n",
    "sub_node_parsers = [\n",
    "    SimpleNodeParser.from_defaults(chunk_size=c, chunk_overlap=20) for c in sub_chunk_sizes\n",
    "]\n",
    "\n",
    "all_nodes = []\n",
    "for base_node in base_nodes:\n",
    "    for n in sub_node_parsers:\n",
    "        sub_nodes = n.get_nodes_from_documents([base_node])\n",
    "        sub_inodes = [\n",
    "            IndexNode.from_text_node(sn, base_node.node_id) for sn in sub_nodes\n",
    "        ]\n",
    "        all_nodes.extend(sub_inodes)\n",
    "\n",
    "    # also add original node to node\n",
    "    original_node = IndexNode.from_text_node(base_node, base_node.node_id)\n",
    "    all_nodes.append(original_node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict = {n.node_id: n for n in all_nodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19383"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_nodes_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_index_chunk = VectorStoreIndex(all_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_retriever_chunk = vector_index_chunk.as_retriever(similarity_top_k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = retriever_chunk.retrieve(\n",
    "    \"Eric Von Hippe\"\n",
    ")\n",
    "for node in nodes:\n",
    "    display_source_node(node, source_length=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import (\n",
    "    generate_question_context_pairs,\n",
    "    EmbeddingQAFinetuneDataset,\n",
    ")\n",
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [03:08<00:00, 188.63s/it]\n"
     ]
    }
   ],
   "source": [
    "eval_dataset = generate_question_context_pairs([nodes[563]], Settings.llm, num_questions_per_chunk=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "\n",
    "for node in tqdm.tqdm(base_nodes):\n",
    "    file_path = os.path.join(\"eval_dataset\", f\"llama2_eval_dataset_{node.id_}.json\")\n",
    "    if os.path.exists(file_path):\n",
    "        continue\n",
    "    eval_dataset = generate_question_context_pairs([node], Settings.llm)\n",
    "    eval_dataset.save_json(file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "def merge_json_files(input_folder, output_file):\n",
    "    merged_data = []\n",
    "    \n",
    "    # Iterate over all files in the specified folder\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith('.json'):\n",
    "            filepath = os.path.join(input_folder, filename)\n",
    "            \n",
    "            # Open and read the JSON file\n",
    "            with open(filepath, 'r', encoding='utf-8') as file:\n",
    "                data = json.load(file)\n",
    "                merged_data.append(data)\n",
    "    \n",
    "    # Write the merged data to the output file\n",
    "    with open(output_file, 'w', encoding='utf-8') as outfile:\n",
    "        json.dump(merged_data, outfile, indent=4)\n",
    "\n",
    "# Usage\n",
    "input_folder = 'eval_dataset'  # Replace with the path to your folder\n",
    "output_file = 'eval_dataset/llama2_eval_dataset.json'  # Replace with the path to your output file\n",
    "\n",
    "merge_json_files(input_folder, output_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_dataset.save_json(\"llama2_eval_dataset.json\")\n",
    "# eval_dataset = EmbeddingQAFinetuneDataset.from_json(\"data/llama2_eval_dataset.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base\n",
    "base_retriever = vector_index.as_retriever(similarity_top_k=top_k)\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=base_retriever\n",
    ")\n",
    "\n",
    "results_base = await retriever_evaluator.evaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chunk\n",
    "vector_retriever_chunk = vector_index_chunk.as_retriever(\n",
    "    similarity_top_k=top_k\n",
    ")\n",
    "retriever_chunk = RecursiveRetriever(\n",
    "    \"vector\",\n",
    "    retriever_dict={\"vector\": vector_retriever_chunk},\n",
    "    node_dict=all_nodes_dict,\n",
    "    verbose=True,\n",
    ")\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=retriever_chunk\n",
    ")\n",
    "\n",
    "results_chunk = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentence\n",
    "sentence_retriever = sentence_index.as_retriever(\n",
    "    similarity_top_k=top_k,\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "retriever_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    [\"mrr\", \"hit_rate\"], retriever=sentence_retriever\n",
    ")\n",
    "\n",
    "results_sentence = await retriever_evaluator.aevaluate_dataset(\n",
    "    eval_dataset, show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_results_df = get_retrieval_results_df(\n",
    "    [\n",
    "        \"Base Retriever\",\n",
    "        \"Retriever (Chunk References)\"\n",
    "        \"Retriever (window)\"\n",
    "    ],\n",
    "    [results_base, results_chunk, results_sentence],\n",
    ")\n",
    "display(full_results_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentence Window Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.node_parser import SentenceWindowNodeParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the sentence window node parser w/ default settings\n",
    "node_parser = SentenceWindowNodeParser.from_defaults(\n",
    "    window_size=3,\n",
    "    window_metadata_key=\"window\",\n",
    "    original_text_metadata_key=\"original_text\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceWindowNodeParser(include_metadata=True, include_prev_next_rel=True, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x00000179D2D7F9D0>, id_func=<function default_id_func at 0x00000179C48CE320>, sentence_splitter=<function split_by_sentence_tokenizer.<locals>.<lambda> at 0x0000017A0553F400>, window_size=3, window_metadata_key='window', original_text_metadata_key='original_text')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_nodes = node_parser.get_nodes_from_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_index = VectorStoreIndex(sentence_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.indices.postprocessor import MetadataReplacementPostProcessor\n",
    "\n",
    "query_engine = sentence_index.as_query_engine(\n",
    "    similarity_top_k=5,\n",
    "    # the target key defaults to `window` to match the node_parser's default\n",
    "    node_postprocessors=[\n",
    "        MetadataReplacementPostProcessor(target_metadata_key=\"window\")\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window_response = query_engine.query(\n",
    "    \"Can you tell me about the key concepts the prospective study around food security\"\n",
    ")\n",
    "print(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window: Intern ational Assessmen t of Agricult ural \n",
      "Knowledge, Sci ence & Technology fo r Development.  Gl obal Report.    \n",
      " - IFPRI  (2005 ).  New Risks and Opportunities for Food Security: sc enarios analyses for 2015 and \n",
      "2050.  \n",
      " 6.1.2.2.   Les études pro spective s ciblan t les re ssources  marine s  \n",
      "- Plan b leue (2017 ).  Vers un nouvel exerc ice de prospective sur l’environnemen t et le \n",
      "développement en  Méditer ranée : Rapport de bench mark des é tudes exist antes . \n",
      "\n",
      "------------------\n",
      "Original Sentence: New Risks and Opportunities for Food Security: sc enarios analyses for 2015 and \n",
      "2050.  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# check the original sentence that was retrieved for each node, as well as the actual window of sentences that was sent to the LLM.\n",
    "window = window_response.source_nodes[0].node.metadata[\"window\"]\n",
    "sentence = window_response.source_nodes[0].node.metadata[\"original_text\"]\n",
    "\n",
    "print(f\"Window: {window}\")\n",
    "print(\"------------------\")\n",
    "print(f\"Original Sentence: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on the provided context information, some examples of orientations strategic mentioned in the documents related to agricultural and fisheries systems that can be used for the analysis of a prospective strategy in 2035 are:\n",
      "\n",
      "1. Orientations stratégiques MAI-Tend et MDM-Mondia (page 599)\n",
      "2. Préservation des ressources productives (terres, eau, sols…), résilience aux changements climatiques et utilisation des ressources non conventionnelles\n",
      "3. Développement des institutions professionnelles et participation\n",
      "4. Substitution aux importations (filières céréales, laits…. ) et contribution au réquilibrage de la balance alimentaire par l'export\n",
      "\n",
      "These examples can be used as a starting point for the analysis of a prospective strategy in 2035 for the agricultural and fisheries systems.\n",
      "\n",
      "Please note that these answers are generated based on the provided context information, without prior knowledge or external research.\n"
     ]
    }
   ],
   "source": [
    "window_response = query_engine.query(\n",
    "    \"Donnes des exemples mentionnés dans les documents de politiques de soutien aux systèmes productifs agricoles et halieutiques pour l'analyse stratégique prospective en 2035\"\n",
    ")\n",
    "print(window_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
